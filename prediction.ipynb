{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "# para recarregar do modelo quando tiver alguma alteração\n",
    "import importlib\n",
    "#importlib.reload(U)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "from termcolor import colored\n",
    "\n",
    "import utils as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, patch_size):\n",
    "    image = U.load_image(image_path)\n",
    "    image_data = U.convert_to_array(image)\n",
    "    image_data[np.isnan(image_data)] = 0 # adiciona 0 onde é NaN\n",
    "    image_data = U.normalize_(image_data)\n",
    "\n",
    "    \"\"\"mask = U.load_image(mask_path)\n",
    "    mask_data = U.convert_to_array(mask)\n",
    "    mask_data[np.isnan(mask_data)] = 0 # adiciona 0 onde é NaN\n",
    "    mask_data[mask_data>0] = 1\n",
    "    mask_data[mask_data<=0] = 0\n",
    "    \"\"\"\n",
    "\n",
    "    all_images = []\n",
    "    ps = patch_size\n",
    "    for i in range(0, image_data.shape[1], ps):\n",
    "        for j in range(0, image_data.shape[1], ps):\n",
    "            img = image_data[i:i+ps,j:j+ps,:]\n",
    "            #img = img[:,:,[0,1,2,6,7,9,13,14]]\n",
    "            all_images.append(img)\n",
    "\n",
    "    images = np.array(all_images)\n",
    "    \n",
    "    return image, image_data, images#, mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./Models/deforestation_trained_model_samples_mapbiomas_unet2_3.h5\", custom_objects={'soft_dice_loss': U.soft_dice_loss, 'iou_coef': U.iou_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(images, patch_size):\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    predictions = predictions.squeeze()\n",
    "\n",
    "    predicted = np.zeros((256, 256))\n",
    "    \n",
    "    ps = patch_size\n",
    "    x = 0\n",
    "    for i in range(0, 256, ps):\n",
    "        for j in range(0, 256, ps):\n",
    "            predicted[i:i+ps, j:j+ps] += predictions[x]\n",
    "            x += 1\n",
    "    \n",
    "    predicted = np.where(predicted > 0.5, 1, 0)\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(image_data, mask_data, predicted):\n",
    "\n",
    "    f = plt.figure(figsize=(20,20))\n",
    "\n",
    "    f.add_subplot(3, 3, 1)\n",
    "    # 2 = B4, 1 = B3, 0 = B2\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image_data[:,:,[2,1,0]]))\n",
    "    plt.title('Image')\n",
    "\n",
    "    f.add_subplot(3, 3, 2)\n",
    "    plt.imshow(mask_data)\n",
    "    plt.title('Truth mask')\n",
    "\n",
    "    f.add_subplot(3, 3, 3)\n",
    "    plt.imshow(predicted)\n",
    "    plt.title('Prediction')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(predicted_images):\n",
    "    output = 'Data/Predicted/test_samples_mapbiomas_unet2_3_test2.tif'\n",
    "    os.system('gdal_merge.py -n 0 -co COMPRESS=PACKBITS -co BIGTIFF=YES -of gtiff {0} -o {1}'.format(predicted_images, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 8) for input Tensor(\"input_2:0\", shape=(None, 64, 64, 8), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 1024, 8).\n",
      "\u001b[31mSpent time: 00:01:18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "images_path = 'Data/BuildingsDataSet/Prediction/Images/'\n",
    "#masks_path = 'Data/BuildingsDataSet/Prediction/Masks/'\n",
    "\n",
    "patch_size = 64\n",
    "predicted_images = []\n",
    "file_out_n = 'Data/Predicted/teste'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "files = next(os.walk(images_path))[2]\n",
    "for i, image_name in enumerate(files):\n",
    "\n",
    "    image_path = images_path + image_name\n",
    "    #mask_path = masks_path + image_name\n",
    "    \n",
    "    image, image_data, images = read_image(image_path, patch_size)\n",
    "    predicted = render_prediction(images, patch_size)\n",
    "    #show_predictions(image_data, mask_data, predicted)\n",
    "    \n",
    "    output = '{0}{1}.tif'.format(file_out_n, i)\n",
    "    U.convert_to_raster(image, predicted, output)\n",
    "    \n",
    "    predicted_images.append(output)\n",
    "    \n",
    "predicted_images = \" \".join(predicted_images)\n",
    "\n",
    "merge_images(predicted_images)\n",
    "\n",
    "# após fazer o merge deleta as imagens\n",
    "os.system('rm -rf {0}*'.format(file_out_n))\n",
    "\n",
    "# spent time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(colored('Spent time: {0}'.format(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))), 'red'))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
